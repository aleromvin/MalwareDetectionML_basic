# Experimenting with machine learning models for malware detection

**\*\*\*DISCLAIMER: This project doesn't make any definitive claims about its capabilities to detect malware, although we do think it does work well enough (we would still upload suspicious files to virustotal before executing them)\*\*\***

## Introduction

This is a project I made as an assignment for one of my university subjects. It is mostly based on the article "A learning model to detect maliciousness of portable executable using integrated feature set" by Ajit Kumar, K.S. Kuppusamy and G. Aghila. In this project I take on a double objective: on the one hand, the project attempts to document and illustrate (a simplified version of) the typical workflow of a data scientist; on the other hand, it also attempts to train several classification algorithms that should be able to tell apart benevolent from malicious files based on [PE](https://en.wikipedia.org/wiki/Portable_Executable) header characteristics. In this latter regard, the end result is an interactive application (the `interactive.Rmd` file) where the user may upload a file to receive a response from one or several of the algorithms about its predicted class (malware or safe).

The following is a list of the most important scripts and files in the repository:

* The `interactive.Rmd` file contains the static content and the script of the main app.
* The `scripts/models1.R` file contains the code for building the models. The R workspace generated in this script is stored in the `modelos/models1.RData` file.
* The `datos/` directory contains the datasets used in this project. This data is taken from [Ajit Kumar's repository](https://github.com/urwithajit9/ClaMP/tree/master/dataset). More specifically, the dataset we used is the `ClaMP_Integrated-5184.arff` file.
* The `scripts/plots.R` file contains the code for creating the plots and graphs that are referenced in the app markdown.
* The `scripts/PE_feature_extraction.py` file contains the code for extracting the features from a file that is uploaded to the main app.
* The `peid.yara` file contains the PEiD's packers signature converted to yara rules. I actually didn't write this, it is also taken from [Ajit Kumar's repository](https://github.com/urwithajit9/ClaMP/tree/master/dataset).

A list of the most important references used in the making of this project can be found in the `references.md` file. There is also another file, `links.txt`, where I have been hoarding most of the pages that I have found useful at some moment. 

An online instance of this app will soon be hosted somewhere, but, in the meantime (or alternatively), the reader can obviously choose to deploy it locally. Instructions for this are given in the following section of this `README.md` file. The app (the `interactive.Rmd` file) is pretty self-explanatory, so I think that's a good enough introduction.

## Requirements and instructions for local deployment

If the reader wants to deploy the `interactive.Rmd` locally on their PC, they will require the following software:

* A functioning installation of the R language. The project was made in the 4.3.0 version, however it will probably work on older versions too.

* The packages used, directly or indirectly, in the "interactive.Rmd" script, are obviously also required for the app to function. In the future I will add a list with all these packages here.

* A functioning installation of the python language. The project was made in the 3.11.3 version, however, same as before.

* The following python packages have to be installed: `pefile, yara-python`. You can install them via pip, e.g.: `pip install yara-python`. **Note:** There is another python package called `yara`. This is NOT the package that you have to install. 

* I don't think you have to install the [yara](https://github.com/plusvic/yara) software itself; however, if something doesn't work for you, try installing it (I have it installed and everything works right for me).

Once you have these software and packages installed, just clone this repository anywhere in your computer and deploy the `interactive.Rmd` app however you want (the simplest "normie" way is probably through RStudio, however there are cooler ways to do it from the command line and stuff). Also, I wrote this project on a Linux OS, so I don't know how well (if at all) it will work on other OSs.

Actually, you don't really need to have the whole repository. If I'm not mistaken, the only files you actually need are:

* The `interactive.Rmd` file
* All the graphs and images. Alternatively, you can generate them with the `plots.R` script in the `scripts` folder.
* The `datos` folder with the `ClaMP_Integrated-5184.arff` file inside
* The `scripts` folder with the `PE_feature_extraction.py` and `peid.yara` scripts
* The `modelos` folder with the `models1.RData` file (contains the fitted models). Alternatively, you can generate these models with the `models1.R` script in the `scripts` folder.

I think that's it. **Important:** you obviously do have to keep the same directory structure as in the repository for the app to work.

## Methodology

As I have already stated, the approach in this project is mostly based on an article by Ajit Kumar, K.S. Kuppusamy and G. Aghila, of which a copy can be found [here](https://www.sciencedirect.com/science/article/pii/S1319157817300149). For the initial model, an already constructed [dataset](https://github.com/urwithajit9/ClaMP/tree/master/dataset) has been used. The previous link actually contains two datasets, each of them in two formats (.csv and the lesser known, though in some ways more convenient and equally open source [.arff](https://en.wikipedia.org/wiki/Weka_(machine_learning))). I have used the .arff file for the "integrated" dataset. For any reader who wants an additional insight about how this dataset differs from the "raw" dataset, I refer them to the previously mentioned article. In summary, though, the "raw" dataset includes features that are obtained directly from PE headers, while the "integrated" dataset also includes features that are derived from the ones in the "raw" dataset + a set of rules based on what a "standard" PE file should look like (the reasoning behind this is that if a PE file differs greatly from these rules, it is reasonable to think that the probabilities of it being malicious also increase).

I have also recycled many of the functions in Ajit Kumar's [scripts](https://github.com/urwithajit9/ClaMP/tree/master/scripts) for this project, mainly for extracting the features of the file that the user may upload to the app for analysis. To be honest, I am greatly indebted to this man, and I hope he has a very nice day every day from now on.

One of my goals with this project is to replicate these datasets with a custom dataset aggregated by myself, using samples from [virusshare](https://virusshare.com/). However this is still a work in progress.

I am accustomed to work on a Linux environment, which has been positive from a security standpoint as it has made it less likely to infect my system with unwanted malware via accidental execution, as Portable Executable files are a Windows standard. Still, I have considered setting up a network of virtual machines that is as isolated from the outside world as possible, to guarantee my computer's and my network's safety throughout the most sensitive parts of this project, though as of yet I have not done this.

