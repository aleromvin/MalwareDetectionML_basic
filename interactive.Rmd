---
title: "Malware Detection with ML"
output:
  flexdashboard::flex_dashboard:
    theme: readable
    source: https://github.com/aleromvin/MalwareDetectionML_basic
runtime: shiny
author: Alexander Romero Vinogradov
email: aleromvin@gmail.com
---

```{r setup, include=FALSE}

# Libraries

library(tidyverse)
library(tidymodels)
library(farff)
library(ggplot2)
library(ggnewscale)
library(DT)
library(htmltools)
library(corrplot)
library(knitr)
library(xtable)
# library(reticulate)

# Increase shiny request size for uploading bigger files
options(shiny.maxRequestSize=30*1024^2)

# Functions, data and parameters

readARFF("datos/ClaMP_Integrated-5184.arff") %>% 
  select(-packer) -> malware

malware$class <- recode(malware$class, `0` = "Benign", `1` = "Malware")

numericas <- malware %>% select(where(is.numeric)) %>% colnames()
categoricas <- malware %>% select(-where(is.numeric)) %>% select(-class) %>% colnames()

escapequotes <- function(a){
  
  a <- gsub("'", "'\''", a)
  
  a <- paste0("'", a, "'")
  
  return(a)
  
}

# Code for "interactive plots"

neglog <- function(x) {sign(x) * log(1 + abs(x))}

# For boxplots:

interactive_boxplot <- function(dataset, varname, geomtype = "boxplot", apply_transformation = "none") {
  
  # Manual colour scale for classes
  
  classColors <- c("blue", "red")
  names(classColors) = levels(malware$class)
  classColScale <- scale_colour_manual(name = "class",values = classColors)
  
  # Set geometry function
  
  if (geomtype == "boxplot") (geomfun = geom_boxplot) else if (geomtype == "violin") (geomfun = geom_violin)
  
  # Decide to apply transformation or not
  
  if (apply_transformation == "none"){

    p = ggplot(dataset, aes(class, .data[[varname]]))
    
  } else if (apply_transformation == "log") {
    
    p = ggplot(dataset, aes(class, neglog(.data[[varname]])))
    
  } else if (apply_transformation == "asinh") {
    
    p = ggplot(dataset, aes(class, asinh(.data[[varname]])))
  
  }
  
  # Additional plot properties
  
  p = p +
    geomfun(aes(col = class)) +
    labs(title = paste0("Distributions of ",varname," value"),
         subtitle = "By class") +
    xlab("Class") +
    ylab(varname) +  classColScale
  
  p
  
}

# For histograms:

interactive_histogram <- function(dataset, varname, add_poly = TRUE, nbins = 30, apply_transformation = "none", together = TRUE) {
  
  # Manual color scale
  
  classColors <- c("turquoise", "magenta")
  names(classColors) = levels(malware$class)
  classColScale <- scale_colour_manual(name = "class", values = classColors)
  
  if (apply_transformation == "none") {
    
    p = ggplot(dataset, aes(x = .data[[varname]]))
    
  } else if (apply_transformation == "log") {
    
    p = ggplot(dataset, aes(x = neglog(.data[[varname]])))
    
  } else if (apply_transformation == "asinh") {
    
    p = ggplot(dataset, aes(x = asinh(.data[[varname]])))
  
  }
  
  # Additional properties
  
  p = p + geom_histogram(aes(col = class), bins = nbins, alpha = 0.8, position = "identity") +
    labs(title = paste0("Distributions of ",varname," value"),
         subtitle = "By class") +
    xlab(varname) +
    ylab("Number of cases") + classColScale
  
  if (add_poly == TRUE) {
    
    classColors2 <- c("gold", "black")
    names(classColors2) = levels(malware$class)
    classColScale2 <- scale_colour_manual(name = "class", values = classColors2)
    
    p = p + new_scale_color() + geom_freqpoly(aes(color = class), bins = nbins) +
      classColScale2
    
  }
  
  if (together == FALSE) {
    
    p = p + facet_grid(class ~ .)
    
  }

  p
  
}

# For barplots:

interactive_barplot <- function(dataset, varname, together = TRUE) {
  
  # Manual color scale
  
  classColors <- c("turquoise", "magenta")
  names(classColors) = levels(malware$class)
  classColScale <- scale_colour_manual(name = "class", values = classColors)
  classFillScale <- scale_fill_manual(name = "class", values = classColors)
  
  p = ggplot(dataset, aes(x = .data[[varname]]))
    
  # Additional properties
  
  p = p + geom_bar(aes(fill = class, col = class), alpha = 0.5) +
    labs(title = paste0("Number of cases for ",varname),
         subtitle = "By class") +
    xlab(varname) +
    ylab("Number of cases") + classColScale + classFillScale
  
  if (together == FALSE) {
    
    p = p + facet_grid(class ~ .)
    
  }
  
  p
  
}

###########################

# Model data:

load("./modelos/models1.RData")

```

```{css style-addendums, echo = FALSE}

.chart-shim {
    overflow-y: scroll;
    overflow-x: hidden;
    }
    
/* Scrollbar style */

/* Works on Firefox */
* {
  scrollbar-width: thin;
  scrollbar-color: white grey;
}

/* Works on Chrome, Edge, and Safari */
*::-webkit-scrollbar {
  width: 6px;
  height: 6px;
}

*::-webkit-scrollbar-track {
  background: grey;
}

*::-webkit-scrollbar-thumb {
  background-color: white;
  border-radius: 20px;
  border: 1px solid black;
}

/* Justify text */

* {text-align: justify;
  text-justify: inter-word;}

/* Plots */

.myplotclass {
    max-width: min(70%, 500px);
    max-height: min(70%, 500px);
    margin-left: auto;
    margin-right: auto;
    display: block;
    outline-style: solid;
    outline-color: lightgrey;
    outline-width: 1px
}

.myplotclass ~ .figcaption {
    text-align: center;
    display: block;
    margin-left: auto;
    margin-right: auto;
    margin-top: 0.5em;
    margin-bottom: 0.5em;
    color: grey;
    }

caption {
  color: black;
  font-weight: bold;
  font-size: 1.0em;
} 

.myimageclass {
    max-width: min(50%, 400px);
    max-height: min(50%, 400px);
    margin-left: auto;
    margin-right: auto;
    display: block;
    outline-style: solid;
    outline-color: lightgrey;
    outline-width: 1px
}

.myimageclass ~ .figcaption * {
    text-align: center;
    display: block;
    margin-left: auto;
    margin-right: auto;
    margin-top: 0.5em;
    margin-bottom: 0.5em;
    color: grey;
    }

.mywarningparagraph {
    color: red;
    text-align: center;
    display: block;
    margin-left: auto;
    margin-right: auto;
    font-size: 2em;
}

.mywarningparagraph2 {
    color: red;
    text-align: center;
    display: block;
    margin-left: auto;
    margin-right: auto;
    font-size: 1em;
}

.Malware {color: red}

.Benign {color: green}

```

Overview
===

Column {data-width=300 .sidebar}
---

**DISCLAIMER:** This project doesn't make any definitive claims about its capabilities to detect malware, although we do think it does work well enough (we would still upload suspicious files to virustotal before executing them).

<hr>

This app is part a project I made as an assignment for one of my university subjects. It is mostly based on the article "A learning model to detect maliciousness of portable executable using integrated feature set" by Ajit Kumar, K.S. Kuppusamy and G. Aghila. The full code for this project is in the corresponding github repository, which is linked in the top-right corner of this app.

The app itself uses several classification algorithms that should be able to tell apart, with a fair degree of success, malicious from benevolent files based on [PE](https://en.wikipedia.org/wiki/Portable_Executable) header characteristics. It also contains several sections to explore the training data and the performance of the models.

Column
---

### Methodology

![[Image taken from www.tarrdaniel.com](https://www.tarrdaniel.com/documents/Hermetika/kabbala_vilaga.html)](./alchemic-learners.jpg){.myimageclass}

As I have already stated, the approach in this project is mostly based on an article by Ajit Kumar, K.S. Kuppusamy and G. Aghila, of which a copy can be found [here](https://www.sciencedirect.com/science/article/pii/S1319157817300149). For the initial model, an already constructed [dataset](https://github.com/urwithajit9/ClaMP/tree/master/dataset) has been used. The previous link actually contains two datasets, each of them in two formats (.csv and the lesser known, though in some ways more convenient and equally open source [.arff](https://en.wikipedia.org/wiki/Weka_(machine_learning))). I have used the .arff file for the "integrated" dataset. For any reader who wants an additional insight about how this dataset differs from the "raw" dataset, I refer them to the previously mentioned article. In summary, though, the "raw" dataset includes features that are obtained directly from PE headers, while the "integrated" dataset also includes features that are derived from the ones in the "raw" dataset + a set of rules based on what a "standard" PE file should look like (the reasoning behind this is that if a PE file differs greatly from these rules, it is reasonable to think that the probabilities of it being malicious also increase).

I have also recycled many of the functions in Ajit Kumar's [scripts](https://github.com/urwithajit9/ClaMP/tree/master/scripts) for this project, mainly for extracting the features of the file that the user may upload to the app for analysis. To be honest, I am greatly indebted to this man and I hope he has a very nice day everyday from now on.

One of my goals with this project is to replicate these datasets with a custom dataset aggregated by myself, using samples from [virusshare](https://virusshare.com/). However this is still a work in progress.

I am accustomed to work on a Linux environment, which has been positive from a security standpoint as it has made it less likely to infect my system with unwanted malware via accidental execution, as Portable Executable files are a Windows standard. Still, I have considered setting up a network of virtual machines that is as isolated from the outside world as possible, to guarantee my computer's and my network's safety throughout the most sensitive parts of this project, though as of yet I have not done this.


Data visualization
===

Column {data-width=300 .sidebar}
---
    
### Global filters

```{r}

selectInput("dataset", "Dataset:", 
            c("Ajit Kumar" = "malware", "Custom" = "malware2"), selected = "Ajit Kumar")

```

<hr>

```{r}

h4("Filter by numeric variable")

fluidRow(
  column(width = 10, selectInput("global_numerica1.1", "Choose a variable and configure filter options:", c("None",numericas),
                                selected = "None")))

h5("Filter options")

fluidRow(  
  column(width = 4, selectInput("global_numerica1.2", "", c("\u2265","\u2264"))),
  
  column(width = 6, numericInput("global_numerica1.3", "", 0))
)

```

<hr>

```{r}

h4("Filter by categorical variable")

textInput("global_categorica1", "Match existing values of categorical variables:", width = "100%", placeholder = "Type something here if you want")

```

```{r}

dataset <- eventReactive({
  input$dataset
  input$global_numerica1.2
  input$global_numerica1.3
  input$global_categorica1
  },
                    
  {if (input$dataset == "malware") {d<-malware} else if (input$dataset == "malware2") {d <- malware2}
  
  if (input$global_numerica1.1 != "None" && input$global_numerica1.1 %in% numericas) {
    
    if (input$global_numerica1.2 == "\u2265") {
      
      d <- d %>% filter(!!as.symbol(input$global_numerica1.1) >= input$global_numerica1.3)
      
    } else {
      
      d <- d %>% filter(!!as.symbol(input$global_numerica1.1) <= input$global_numerica1.3)
            
    }
    
  }
    
    if (!is.null(input$global_categorica1)) {
      
      # d <- d %>% filter(if_any(any_of(categoricas)), ~ grepl(input$global_categorica1, .x))
      
      d <- d %>% 
        filter_at(vars(any_of(categoricas)), any_vars(grepl(input$global_categorica1, ., ignore.case = T)))

    }
    
    return(d)
    
    }
  
  )

```


Column {.tabset .tabset-fade}
---
   
### Boxplot output

Boxplots are intended for exploring numeric variables. They let us study important properties about their distribution, and are specially useful for detecting statistical anomalies, like outliers. Violin plots are similar, but also include an approximation of the density function of the variable.

For better visualization of variables which are very skewed (this is the case, for example, with "e_*" variables), a logarithmic or inverse hyperbolic sine transformation may be performed.

```{r}

fluidRow(
  
  column(width = 5, selectInput("boxplot_var", "Variable:", numericas,
                                selected = "e_cblp")),
  column(width = 2, radioButtons("boxplot_geom", "Geometry:", c("Boxplot" = "boxplot", "Violin" = "violin"), selected = "boxplot")),
  column(width = 3, selectInput("boxplot_transform", "Apply transformation", c("None" = "none", "log", "asinh"), selected = "None"))
  
)

boxplot_var <- reactive(input$boxplot_var)

boxplot_geom <- reactive(input$boxplot_geom)

boxplot_transform <- reactive(input$boxplot_transform)

renderUI(
  
  if (nrow(dataset()) > 0) {
    
    renderPlot(
      
    interactive_boxplot(dataset(), boxplot_var(), geomtype = boxplot_geom(), apply_transformation = boxplot_transform()) +
                   theme(
    panel.background = element_rect(fill = "lightgreen",
                                  colour = "lightgreen",
                                  linewidth = 0.5, linetype = "solid"),
    panel.grid.major = element_line(linewidth = 0.5, linetype = 'solid',
                                  colour = "white"),
    panel.grid.minor = element_line(linewidth = 0.25, linetype = 'solid',
                                  colour = "white"),
    panel.border = element_rect(colour = "black", fill=NA, linewidth=2)
               )
      
    )
    
  } else {
    
    p("No data to be displayed!", class = "mywarningparagraph")
    
  }
  
)

# renderPlot(
# 
#     interactive_boxplot(dataset(), boxplot_var(), geomtype = boxplot_geom(), apply_transformation = boxplot_transform()) +
#                  theme(
#   panel.background = element_rect(fill = "lightgreen",
#                                 colour = "lightgreen",
#                                 linewidth = 0.5, linetype = "solid"),
#   panel.grid.major = element_line(linewidth = 0.5, linetype = 'solid',
#                                 colour = "white"),
#   panel.grid.minor = element_line(linewidth = 0.25, linetype = 'solid',
#                                 colour = "white"),
#   panel.border = element_rect(colour = "black", fill=NA, linewidth=2)
#              )
# 
# )

# renderPlot(
#   
#   interactive_boxplot(dataset(), "E_data", geomtype = "boxplot", apply_transformation = T)
#   
# )

```


### Histogram output

Histograms are intended for exploring numeric variables. They give us a first impression about the general shape of the distribution of the variable.

For better visualization of variables which are very skewed (this is the case, for example, with "e_*" variables), a logarithmic or inverse hyperbolic sign transformation may be performed.

```{r}

fluidRow(
  
  column(width = 5, selectInput("histogram_var", "Variable:", numericas,
                                selected = "E_file")),
  column(width = 4, sliderInput("histogram_nbins", "Number of bins:", min = 10, max = 60, step = 5, ticks = T, value = 30))
  
)

fluidRow(
  
  column(width = 3, checkboxInput("histogram_add_poly", "Add freq. polygon", value = T)),
  column(width = 3, checkboxInput("histogram_together", "Plot together", value = F)),
  column(width = 3, selectInput("histogram_transform", "Apply transformation", c("None" = "none", "log", "asinh"), selected = "None"))
)

histogram_var <- reactive(input$histogram_var)

histogram_nbins <- reactive(input$histogram_nbins)

histogram_add_poly <- reactive(input$histogram_add_poly)

histogram_together <- reactive(input$histogram_together)

histogram_transform <- reactive(input$histogram_transform)

renderUI(
  
  if (nrow(dataset()) > 0) {
    
    renderPlot(interactive_histogram(dataset(), histogram_var(), nbins = histogram_nbins(), add_poly = histogram_add_poly(), together = histogram_together(), apply_transformation = histogram_transform()) + 
                 theme(
      panel.background = element_rect(fill = "darkgreen",
                                    colour = "darkgreen",
                                    linewidth = 0.5, linetype = "solid"),
      panel.grid.major = element_line(linewidth = 0.5, linetype = 'solid',
                                    colour = "lightgreen"), 
      panel.grid.minor = element_line(linewidth = 0.25, linetype = 'solid',
                                    colour = "lightgreen"),
      panel.border = element_rect(colour = "black", fill=NA, linewidth=2)
                 )
      )
    
  } else {
    
    div("No data to be displayed!", class = "mywarningparagraph")
    
  }
  
)

# renderPlot(interactive_histogram(dataset(), histogram_var(), nbins = histogram_nbins(), add_poly = histogram_add_poly(), together = histogram_together(), apply_transformation = histogram_transform()) + 
#              theme(
#   panel.background = element_rect(fill = "darkgreen",
#                                 colour = "darkgreen",
#                                 linewidth = 0.5, linetype = "solid"),
#   panel.grid.major = element_line(linewidth = 0.5, linetype = 'solid',
#                                 colour = "lightgreen"), 
#   panel.grid.minor = element_line(linewidth = 0.25, linetype = 'solid',
#                                 colour = "lightgreen"),
#   panel.border = element_rect(colour = "black", fill=NA, linewidth=2)
#              )
#   )

```

### Barplot output

Barplots are intended for exploring categorical variables. They enable us to quickly perceive the distribution for the number of occurrences in each category.

```{r}

fluidRow(
  
  column(width = 7, selectInput("barplot_var", "Variable:", categoricas,
                                selected = "FH_char0")),
  column(width = 3, checkboxInput("barplot_together", "Plot together (stacked)", value = T))
  
)

barplot_var <- reactive(input$barplot_var)

barplot_together <- reactive(input$barplot_together)

renderUI(
  
  if (nrow(dataset()) > 0) {
    
    renderPlot(interactive_barplot(dataset(), barplot_var(), together = barplot_together()) + 
                 theme(
      panel.background = element_rect(fill = "darkgreen",
                                    colour = "darkgreen",
                                    linewidth = 0.5, linetype = "solid"),
      panel.grid.major = element_line(linewidth = 0.5, linetype = 'solid',
                                    colour = "lightgreen"), 
      panel.grid.minor = element_line(linewidth = 0.25, linetype = 'solid',
                                    colour = "lightgreen"),
      panel.border = element_rect(colour = "black", fill=NA, linewidth=2)
                 )
      )
    
  } else {
    
    div("No data to be displayed!", class = "mywarningparagraph")
    
  }
  
)

# renderPlot(interactive_barplot(dataset(), barplot_var(), together = barplot_together()) + 
#              theme(
#   panel.background = element_rect(fill = "darkgreen",
#                                 colour = "darkgreen",
#                                 linewidth = 0.5, linetype = "solid"),
#   panel.grid.major = element_line(linewidth = 0.5, linetype = 'solid',
#                                 colour = "lightgreen"), 
#   panel.grid.minor = element_line(linewidth = 0.25, linetype = 'solid',
#                                 colour = "lightgreen"),
#   panel.border = element_rect(colour = "black", fill=NA, linewidth=2)
#              )
#   )

```

### Table output

A table with the filtered data.

```{r}

renderDataTable(datatable(dataset(), options = list(sDom  = '<"top">lrt<"bottom">ip')))
  
```


Malware detection algorithms
===

Column {data-width=300 .sidebar}
---

### Upload a PE File

Typical extensions: .exe, .acm, .ax, .cpl, .dll, .drv, .efi, .mui, .ocx, .scr, .sys, .tsps

```{r}

fileInput(inputId = "uploadedFile", label = "", accept = c(".exe", ".acm", ".ax", ".cpl", ".dll", ".drv", ".efi", ".mui", ".ocx", ".scr", ".sys", ".tsps"))


fluidRow(
  
  column(width = 3),
  
  column(actionButton(inputId = "analyze", label = "Analyze file!", icon = icon("cog")), width = 6),
  
  column(width = 3)
  
  )

```

```{r}

respuestaAnalisis <- reactiveVal(0)

resultadoAnalisis <- reactiveVal(NULL)

resultadoAnalisisAux <- reactive(

  # 0: initial state; 1: no file selected; 2: invalid file (cannot extract features); 3: analysis of file completed (shows results)
  
  if (respuestaAnalisis() == 0) {
    NULL
  } else if (respuestaAnalisis() == 1) {
    p("No file selected!", class = "mywarningparagraph2")
  } else if (respuestaAnalisis() == 2) {
    resultadoAnalisis()
  } else if (respuestaAnalisis() == 3) {
    resultadoAnalisis()
  }
  
)

procesaArchivo <- function(file) {
  
  resultado <- NULL
  
  if (is.null(file)) {return(list(respuesta = 1, resultado = NULL))} else {
    
    pathtofile <- file$datapath

    tryCatch(
      # Try to do this
      
      {
        
        # getresponse <- system2(command = "python",
        #                     args = c("./scripts/PE_feature_extraction.py", pathtofile),
        #                     stdout = TRUE, timeout = 30)
        
        getresponse <- system2(command = "python",
                            args = c("./scripts/PE_feature_extraction.py", escapequotes(pathtofile)),
                            stdout = TRUE, timeout = 30)
        
        read.csv(text = getresponse) %>% 
        select(-packer) %>%
        mutate(across(all_of(categoricas), as.factor)) -> newdata
        
        predict(malware_final_dt_fit %>% extract_workflow(), newdata)$.pred_class %>% 
          as.character() -> prediction1
        predict(malware_final_rf_fit %>% extract_workflow(), newdata)$.pred_class %>% 
          as.character() -> prediction2
        predict(malware_final_mlp_fit %>% extract_workflow(), newdata)$.pred_class %>% 
          as.character() -> prediction3
        
        if (all(sapply(c(prediction1, prediction2, prediction3), function(x) x == "Benign"))) {conclusion_message <- p("Congratulations! Looks like that file isn't malware.", span("We would still check on VirusTotal, though...", class = "irony"), class = "myconclusionclass")} else {conclusion_message <- p("Wow! That file looks dangerous, buddy!", class = "myconclusionclass")}
        
        respuesta <- 3
        
        # resultado <- p("Test realizado")
        
        resultado <- div(
          
          p("Results according to DT: ", span(prediction1, class = prediction1)),
          p("Results according to RF: ", span(prediction2, class = prediction2)),
          p("Results according to MLP: ", span(prediction3, class = prediction3)),
          conclusion_message,
          class = "myresultsclass"
          
        )
        
        return(list(respuesta = respuesta, resultado = resultado))
        
      },
      
      # If an error happens, try to do this
      error = function(e){
        
        print(e)
        
        respuesta <- 2
        
        resultado <- div(p("An error occurred. Are you sure your file is a valid PE file? If the problem persists, please report it as an issue on the project's github page, with the following error: ", pre(paste(e), class = "verbatim"), class = "myerrorparagraph"))
        
        return(list(respuesta = respuesta, resultado = resultado))
        
      },
      
      # If a warning happens, try to do this
      warning = function(e){
        
        print(e)
        
        respuesta <- 2
        
        resultado <- div(p("An error occurred. Are you sure your file is a valid PE file? If the problem persists, please report it as an issue on the project's github page, with the following error: ", pre(paste(e), class = "verbatim"), class = "myerrorparagraph"))
        
        return(list(respuesta = respuesta, resultado = resultado))
        
      }
      
    )
    
    # system2(command = "python", args = c("./scripts/PE_feature_extraction.py", pathtofile))
        
    # resultado <- input$uploadedFile$datapath
    # respuesta <- 3
    
  }
  
}

observeEvent(input$analyze, {
  
  respuestaAnalisis(0)
  
  resultadoAnalisis(p("Waiting for results..."))
  
  respuesta_resultado_analisis <- procesaArchivo(input$uploadedFile)
  
  respuestaAnalisis(respuesta_resultado_analisis$respuesta)
  
  resultadoAnalisis(respuesta_resultado_analisis$resultado)
  
  }
             
)

renderUI(resultadoAnalisisAux())

```



Column
---

### Evaluating model performances

*The code for generating the plots in this report can be found in the `plots.R` script*

#### Preliminary observations about the data itself

As we can see in the [visualization](./#section-data-visualization), one of the possible problems that we could have with this data is that some variables have extremely skewed distributions. However, this is not that much of a problem for the kinds of models that we are building (specially for the ones involving tree structures), and, in any case, we have applied anti-skewness transformations to the most problematic variables.

Another typical problem for machine learning models is high correlation between variables. Thankfully, most variables in our dataset are not highly correlated. The following graphs are representations of the correlation matrices for the numeric variables, before and after their anti-skewness transformation:

![Before transformation](./corrplot1.png){.myplotclass}

![After transformation](./corrplot2.png){.myplotclass}

#### Model Performances

For comparison purposes, three different kinds of machine learning models have been built: a Decision Tree model, which we deemed specially useful for interpretation purposes; a Random Forest model, which is also good in this regard but has the added benefit of also working better in its classification task (as we will see); and, last but not least, a MultiLayer Perceptron, which is the hardest to interpret but also works quite well (this one and the Random Forest have basically the same performance on all considered metrics, except specificity, for which MLP yields marginally better results).

![Representation of the Decision Tree](./visualizeDT.png){.myplotclass}

![A graph of the importance of variables in the Random Forest model](./visualizeRF.png){.myplotclass}

![Representation of the MultiLayer Perceptron (does this image tell you anything?)](./visualizeMLP.png){.myplotclass}

For the importance of variables in the Random Forest model, an impurity metric has been used. More information about this can be found in [this page](https://rstudio-pubs-static.s3.amazonaws.com/255596_70d1823f6a214d58970f39af709dad37.html#importancia-de-predictores) (if you know spanish it may be easier to understand, though most automatic translators nowadays work well enough).

For measuring the performance of these models we will use two very typical approaches: using a training-test split and cross-validation. Another approach that could have been used for the Random Forest model is OutOfBag error (perhaps we'll add this in the future).

*Note:* the reader should take into account that the "Malware" class was treated as the "negative" class when building these models, therefore "sensibility" and "specificity" refer to "Benevolent" as the "positive" class. This may be a bit confusing as the goal of these models is to detect malware, so "sensibility" should be "the probability of correctly classifying a PE file as malware", but in this case this is specificity. The next time we build machine learning models we will have this in mind.

##### Training-Test Split

To evaluate the "extrapolating power" of our models (a fancy way of saying "to evaluate how good their predictions given new data are"), we check how well it classifies the observations in a test subset of our dataset, separate from the training subset used for (obviously) training the model.

```{r}

malware_final_dt_fit %>% collect_metrics() %>% 
  select(-c(.config, .estimator)) %>% 
  kable(caption = "Decision Tree: performance metrics estimations via test split")

malware_final_rf_fit %>% collect_metrics() %>% 
  select(-c(.config, .estimator)) %>% 
  kable(caption = "Random Forest: performance metrics estimations via test split")


malware_final_mlp_fit %>% collect_metrics() %>% 
  select(-c(.config, .estimator)) %>% 
  kable(caption = "MultiLayer Perceptron: performance metrics estimations via test split")
```

###### Confusion matrices for each model (columns = truth / rows = estimates):

```{r}
malware_final_dt_predictions %>% conf_mat(truth = class, estimate = .pred_class) %>% 
  .$table %>% kable(caption = "Decision Tree: Confusion Matrix")

malware_final_rf_predictions %>% conf_mat(truth = class, estimate = .pred_class) %>% 
  .$table %>% kable(caption = "Random Forest: Confusion Matrix")

malware_final_mlp_predictions %>% conf_mat(truth = class, estimate = .pred_class) %>% 
  .$table %>% kable(caption = "MultiLayer Perceptron: Confusion Matrix")
```

###### ROC-curves, together and for each model:

```{r}

preds <- list(malware_final_dt_predictions, malware_final_rf_predictions, malware_final_mlp_predictions)

rocdata <- tibble()
i = 0
modelnames = c("DT", "RF", "MLP")
for (pred in preds) {
  i = i + 1

  rocdata_new = roc_curve(pred, truth = class, .pred_Benign)
  rocdata_new$model = modelnames[i]
  rocdata <- bind_rows(rocdata,rocdata_new)

}

modelcolors <- c("green", "darkgreen", "cyan")
names(modelcolors) = modelnames
modelcolScale <- scale_colour_manual(name = "model",values = modelcolors)

rocdata %>%
  ggplot(aes(x = 1 - specificity, y = sensitivity, color = model)) +
  geom_path() +
  geom_abline(lty = 3) +
  coord_equal() +
  theme_bw() +
  labs(title = "ROC curves for all models", subtitle = "Confusingly enough, malware is the negative class") + modelcolScale # Together

rocplots <- vector(mode = "list", length = 3)
i = 0
for (name in modelnames) {

  i = i + 1

  g = rocdata %>%
    filter(model == name) %>%
    ggplot(aes(x = 1 - specificity, y = sensitivity, color = model)) +
    geom_path() +
    geom_abline(lty = 3) +
    coord_equal() +
    theme_bw() +
    labs(title = paste0("ROC curves for ",name," model"), subtitle = "Confusingly enough, malware is the negative class") + modelcolScale # Together

  rocplots[[i]] <- g

}

```


```{r}

rocplots[[1]] %>% plot()

```

```{r}

rocplots[[2]] %>% plot()

```

```{r}

rocplots[[3]] %>% plot()

```

##### Cross-Validation

One of the advantages of using cross-validation is that, on top of giving us a separate (though probably not as robust) estimation of the performance metrics that we had already calculated using the test subset of our dataset, it also, and more importantly in this case, lets us examine if there are huge variations in performance between models trained with slightly different training data (which would obviously be a bad thing).

```{r}

dt_tuning %>% collect_metrics(summarize = F) %>% 
  filter(.config == "Preprocessor1_Model3") -> dt_cv_metrics

dt_tuning %>% collect_metrics() %>% 
  filter(.config == "Preprocessor1_Model3") -> dt_cv_metrics_summarized

# RF

rf_tuning %>% collect_metrics(summarize = F) %>% 
  filter(.config == "Preprocessor1_Model1") -> rf_cv_metrics

rf_tuning %>% collect_metrics() %>% 
  filter(.config == "Preprocessor1_Model1") -> rf_cv_metrics_summarized

# MLP

mlp_tuning %>% collect_metrics(summarize = F) %>% 
  filter(.config == "Preprocessor1_Model4") -> mlp_cv_metrics

mlp_tuning %>% collect_metrics() %>% 
  filter(.config == "Preprocessor1_Model4") -> mlp_cv_metrics_summarized


dt_cv_metrics_summarized %>% 
  select(.metric, mean, std_err) %>% 
  kable(caption = "Decision Tree: performance metrics estimations via CV (summarized)")

rf_cv_metrics_summarized %>% 
  select(.metric, mean, std_err) %>% 
  kable(caption = "Random Forest: performance metrics estimations via CV (summarized)")

mlp_cv_metrics_summarized %>% 
  select(.metric, mean, std_err) %>% 
  kable(caption = "MultiLayer Perceptron: performance metrics estimations via CV (summarized)")

dt_cv_metrics %>%
  select(id, .metric, .estimate) %>%
  spread(.metric, .estimate) %>%
  kable(caption = "Decision Tree: performance metrics estimations via CV")

rf_cv_metrics %>%
  select(id, .metric, .estimate) %>%
  spread(.metric, .estimate) %>%
  kable(caption = "Random Forest: performance metrics estimations via CV")

mlp_cv_metrics %>%
  select(id, .metric, .estimate) %>%
  spread(.metric, .estimate) %>%
  kable(caption = "MultiLayer Perceptron: performance metrics estimations via CV")

```

